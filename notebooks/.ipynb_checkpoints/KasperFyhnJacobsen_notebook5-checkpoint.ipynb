{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5: for-loops\n",
    "#### Kasper Fyhn Jacobsen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Hoff's and Hart and Risley's findings\n",
    "Both the article by Hoff and the article by Hart and Risley find quantitative evidence for socioeconomic status being a cause for slower growth in vocabulary development in children in their first years of learning, which in turn can have an effect on IQ and language skills later in life. Hoff does this by comparing two points in time ten weeks apart and narrowing down correlational effects to SES and vocabulary growth. Hart and Risley do it with a longitudinal study spanning over two and a half years which show the differing trajectories of vocabulary growth between different families of different SESâ€™s and substantial gap in cumulative stimulus measured in words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "### Question 1: Adapting the line\n",
    "Let's make it short, yet understandable, and generalizable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input a sentence and hit enter: The farmer killed the duckling.\n",
      "The mean length of words in the sentence \"The farmer killed the duckling.\" is 5.2.\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation as punct\n",
    "\n",
    "# get a sentence\n",
    "sent_orig = input('Please input a sentence and hit enter: ')\n",
    "# clean it and keep the original for later\n",
    "sent = sent_orig.lower()\n",
    "sent = ''.join(c for c in sent if c not in punct)\n",
    "# tokenize and calculate mean word length\n",
    "tokens = sent.split()\n",
    "words = len(tokens)\n",
    "chars = sum(len(word) for word in tokens)\n",
    "mean_word_len = chars / words\n",
    "# report results\n",
    "print(f'The mean length of words in the sentence \"{sent_orig}\" is {mean_word_len}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 and 3: Doing calculations for many texts\n",
    "As you might have noticed, I am a fan of generalizable (and thereby reusable) code, i.e. code that is made in such a way that it can work for any similar problems.\n",
    "\n",
    "Of course, this quickly leads to the idea of object-oriented programming. So, in this case, we can make a class which is in some way a representation of our text with some attributes and methods. Then, ideally, as we keep on working with texts like this, the class can be extended and improved without having to change all the scripts that use it.\n",
    "\n",
    "Another good thing about making a class like this is that it makes for a nice and easy-to-handle data structure; all info tied to a specific text is stored with the text in little pack, i.e. an object.\n",
    "\n",
    "So, following some the things that we have done with texts so far, we can make a class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation as punct\n",
    "from collections import Counter\n",
    "\n",
    "class TextStats:\n",
    "    '''This class holds a text and can return different stats about it.'''\n",
    "  \n",
    "    def __init__(self, filepath):\n",
    "        try:\n",
    "            file = open(filepath, 'r', encoding='utf-8')\n",
    "            # save name, raw text and cleaned text\n",
    "            self.name = file.name\n",
    "            text = file.read()\n",
    "            self.raw_text = text\n",
    "            self.clean_text = ''.join(c for c in text if c not in punct)\n",
    "            self.clean_text = self.clean_text.lower()\n",
    "            # make tokens and types lists\n",
    "            self.tokens = self.clean_text.split()\n",
    "            self.types = set(self.tokens)\n",
    "        except IOError as e:\n",
    "            print('An error occured when loading: ' + filepath)\n",
    "            print('Error message:', e)\n",
    "\n",
    "    def ttr(self):\n",
    "        '''Return type-to-token ratio'''\n",
    "        \n",
    "        return len(self.types) / len(self.tokens)\n",
    "    \n",
    "    def mean_word_length(self):\n",
    "        '''Return mean word length, only counting alpha tokens.'''\n",
    "          \n",
    "        tokens = [word for word in self.tokens if word.isalpha()]\n",
    "        chars = sum(len(word) for word in tokens)\n",
    "        words = len(tokens)\n",
    "        return chars / words\n",
    "    \n",
    "    def word_freqs(self, n=None):\n",
    "        '''Return a list of n tuples (all if n is not passed with a specific\n",
    "        number) of types and their frequencies, i.e. number of tokens. The list\n",
    "        is sorted from the most frequent and decreasing.'''\n",
    "        \n",
    "        freqs = Counter(self.tokens)\n",
    "        if n > len(self.tokens): # if n is larger than the number of tokens\n",
    "            return freqs.most_common() # return list of all elements\n",
    "        else:\n",
    "            return freqs.most_common(n)\n",
    "    \n",
    "    def print_stats(self):\n",
    "        '''Print a stat summary for the text including number of tokens and\n",
    "        types, type-to-token ratio, mean word length and ...'''\n",
    "        \n",
    "        spc = 7\n",
    "        print(f'Stats for {self.name}')\n",
    "        print(f'Tokens:\\t\\t{len(self.tokens):{spc}}')\n",
    "        print(f'Types:\\t\\t{len(self.types):{spc}}')\n",
    "        print(f'Type-to-token:\\t{self.ttr():{spc}.3}')\n",
    "        print(f'Mean word lgth:\\t{self.mean_word_length():{spc}.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a class into which we can load all texts in a given directory, e.g. all the Austen texts. This script report both the mean word length of all novels as well as the average of the mean word lengths (which are different things as far as I know!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please, paste in the absolute path to the folder of texts: C:\\Users\\Kasper Fyhn Jacobsen\\Dropbox\\Child Language Acquisition\\Jane-Austen\n",
      "Stats for Austen-Emma.txt\n",
      "Tokens:\t\t 157440\n",
      "Types:\t\t  11054\n",
      "Type-to-token:\t 0.0702\n",
      "Mean word lgth:\t   4.33\n",
      "\n",
      "Stats for Austen-Mansfield.txt\n",
      "Tokens:\t\t 159540\n",
      "Types:\t\t   9406\n",
      "Type-to-token:\t  0.059\n",
      "Mean word lgth:\t   4.32\n",
      "\n",
      "Stats for Austen-Northanger.txt\n",
      "Tokens:\t\t  77070\n",
      "Types:\t\t   7223\n",
      "Type-to-token:\t 0.0937\n",
      "Mean word lgth:\t   4.39\n",
      "\n",
      "Stats for Austen-Persuasion.txt\n",
      "Tokens:\t\t  83281\n",
      "Types:\t\t   6004\n",
      "Type-to-token:\t 0.0721\n",
      "Mean word lgth:\t   4.38\n",
      "\n",
      "Stats for Austen-Pride.txt\n",
      "Tokens:\t\t 121533\n",
      "Types:\t\t   7818\n",
      "Type-to-token:\t 0.0643\n",
      "Mean word lgth:\t    4.4\n",
      "\n",
      "Stats for Austen-Sense.txt\n",
      "Tokens:\t\t 118563\n",
      "Types:\t\t   7417\n",
      "Type-to-token:\t 0.0626\n",
      "Mean word lgth:\t   4.43\n",
      "\n",
      "Mean word length of all: 4.43\n",
      "Average of mean word lengths: 4.38\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# set the path to the directory\n",
    "path = input('Please, paste in the absolute path to the folder of texts: ')\n",
    "os.chdir(path)\n",
    "\n",
    "# make a list of TextStats object, one for each text\n",
    "tstats = [TextStats(file) for file in os.listdir()]\n",
    "\n",
    "# print stats for each text\n",
    "for text in tstats:\n",
    "    text.print_stats()\n",
    "    print()\n",
    "\n",
    "# calculate and report mean word length of all novels\n",
    "tokens_all = [word for word in text.tokens\n",
    "              for text in tstats\n",
    "              if word.isalpha()]\n",
    "chars = sum(len(word) for word in tokens_all)\n",
    "words = len(tokens_all)\n",
    "mean_all = chars/words\n",
    "print(f'Mean word length of all: {mean_all:.3}')\n",
    "\n",
    "# calculate and report \"the grand average\", i.e. average of all mean values\n",
    "avs = [text.mean_word_length() for text in tstats]\n",
    "grand_av = sum(avs) / len(avs)\n",
    "print(f'Average of mean word lengths: {grand_av:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
